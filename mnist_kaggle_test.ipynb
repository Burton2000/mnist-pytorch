{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle gives us mnist train/test data in csv files. First column of train is the label and the other 784 columns are the pixel values of the 28x28x1 images. We use pandas to load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the train and test data.\n",
    "train_data = pd.read_csv('./mnist_pytorch/train.csv')\n",
    "test_data = pd.read_csv('./mnist_pytorch/test.csv')\n",
    "#train_data.head(3)  # Sanity check display the first 3 elements of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate the labels from the input data.\n",
    "train_y = train_data.values[:,0]\n",
    "train_x = train_data.values[:,1:].astype(np.float32)\n",
    "test_x = test_data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate how much of our training data is for train and validation.\n",
    "VALIDATION_PERCENT = 0\n",
    "num_train = len(train_y)\n",
    "num_val = int(num_train*VALIDATION_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape data back to images, transpose to N,C,H,W format for pytorch. \n",
    "\n",
    "train_x = train_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "test_x = test_x.reshape([-1, 28, 28, 1]).transpose((0,3,1,2))\n",
    "\n",
    "# Split for train/val.\n",
    "val_x = train_x[0:num_val]\n",
    "val_y = train_y[0:num_val]\n",
    "train_x = train_x[num_val:]\n",
    "train_y = train_y[num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzxjweyIwiXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5460a6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to see an example and print its label.\n",
    "example_im = train_x[0,0,:,:]\n",
    "plt.imshow(example_im)\n",
    "plt.show()\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pytorch dataset wrapper by creating a class that inherits from Dataset. Will be used to store our datasets so we can use the pytorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y=None):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.data[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "val_dataset = MnistDataset(val_x, val_y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our CNN model for classifying our digits data. Define it as a class inheriting from nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.max2x2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(in_features=7*7*32, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.out = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        act1 = self.relu(self.conv1(x))\n",
    "        act2 = self.max2x2(act1)\n",
    "        act3 = self.relu(self.conv2(act2))\n",
    "        act4 = self.max2x2(act3)\n",
    "        flatten = act4.view(-1, 7*7*32)\n",
    "        act5 = self.relu(self.fc1(flatten))\n",
    "        act6 = self.relu(self.fc2(act5))\n",
    "        out = self.out(act6)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_func, optimizer, epochs = 10):\n",
    "    \n",
    "    # Switch to train mode (for things like Batch norm and dropout).\n",
    "    model.train()\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "\n",
    "            # Convert our batch to Variable \n",
    "            x_batch, y_batch = Variable(x_batch), Variable(y_batch)\n",
    "            \n",
    "            # Compute output and loss.\n",
    "            output = model(x_batch)\n",
    "            loss = loss_func(output, y_batch)\n",
    "        \n",
    "            # Zero our gradients/backprop and perform and SGD step.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(loss)           \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function.\n",
    "model = MnistCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1432\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  8.2731\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  2.7176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  6.0942\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  1.4390\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  0.1432\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       " 1.00000e-02 *\n",
       "   8.2731\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       " 1.00000e-02 *\n",
       "   2.7176\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       " 1.00000e-03 *\n",
       "   6.0942\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       " 1.00000e-02 *\n",
       "   1.4390\n",
       " [torch.FloatTensor of size 1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our model.\n",
    "train_model(model, train_dataloader, loss_func, optimizer, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    num_incorrect = 0\n",
    "    for i_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        x_batch, y_batch = Variable(x_batch), Variable(y_batch)\n",
    "                \n",
    "        output = model(x_batch)\n",
    "\n",
    "        _, output = torch.max(output, dim = 1 )\n",
    "        \n",
    "        num_incorrect += torch.sum(output == y_batch)\n",
    "\n",
    "    return num_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_incorrect = test_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(total_incorrect, total):\n",
    "    accuracy = (total - total_incorrect) / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if VALIDATION_PERCENT > 0:\n",
    "    accuracy = calc_accuracy(num_incorrect.data.numpy(), len(val_dataset))\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our test set through to predict labels then save to csv for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(test_x)\n",
    "test_labels = []\n",
    "for i in range(len(test_x)):\n",
    "    \n",
    "    test_batch = Variable(test_x[i].unsqueeze_(0))\n",
    "    \n",
    "    output = model(test_batch)\n",
    "    _, output = torch.max(output, dim = 1)\n",
    "    \n",
    "    test_labels.append(int(output.data.numpy()))\n",
    "\n",
    "np.savetxt(\"foo.csv\", test_labels, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
